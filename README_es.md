[ [English](README.md) ] [ [简体中文](README_zhcn.md) ] [ [繁體中文](README_zhtw.md) ] [ [日本語](README_ja.md) ] [ [한국어](README_ko.md) ] 

# AI Power

La tecnología AI avanza a una velocidad vertiginosa, con nuevos algoritmos y bibliotecas de AI que emergen y evolucionan constantemente. Para capacitar a más personas en el dominio de las últimas innovaciones en AI y participar activamente en proyectos de código abierto, creé AI Power Source. ¡Únete a nosotros en la exploración de la vanguardia de la tecnología AI y contribuye a moldear el futuro!

## Categorías de Artículos

### Aprendizaje de Algoritmos Basado en Código

| Título                | Descripción           | Palabras Clave        |
|-----------------------|-----------------------|-----------------------|
| [Understanding Transformer Attentions](deep_learning/transformer/transformer_attentions.md)                   | Una explicación detallada del mecanismo de atención en los transformadores, cubriendo la auto-atención, la atención multi-cabeza y su implementación en modelos NLP modernos. | Transformers, Self-Attention, MHA |
| [The Vanilla Transformer Explained](deep_learning/transformer/vanilla_transformer_explained_enus.md)       | Una guía comprensiva del modelo de transformer vanilla, detallando su arquitectura, componentes y el proceso de paso hacia adelante para tareas de secuencia a secuencia. | vanilla Transformer, Architecture, Sequence-to-Sequence |
| [Inside CLIP](deep_learning/transformer/model_multimodal/huggingface_clip_explained.md)               | Una explicación detallada del modelo CLIP, cubriendo su arquitectura, proceso de entrenamiento y aplicaciones en la vinculación de imágenes y texto. | CLIP, Architecture |
| [Deep Dive into LLaVA](deep_learning/transformer/model_multimodal/llava_implementation_explained.md)           | Una guía comprensiva de la implementación del modelo LLaVA, explorando su arquitectura, componentes y cómo mejora las tareas de comprensión del lenguaje. | LLaVA, Architecture, MultiModal |
| [Deep Dive into Vision Transformer](deep_learning/transformer/model_vision/huggingface_vit_explained.md)                | Una explicación detallada del modelo Vision Transformer (ViT), detallando su arquitectura, componentes clave y aplicación en tareas de visión por computadora. | Vision Transformer, ViT, Architecture |
| [AutoEncoder Explained](deep_learning/diffusion/autoencoder_explained.md)                    | Una explicación detallada de los autoencoders, su arquitectura, tipos y aplicaciones en compresión de datos y aprendizaje de características. | AutoEncoder, VAE, Architecture |

### API de Huggingface

| Título                | Descripción           | Palabras Clave        |
|-----------------------|-----------------------|-----------------------|
| [Huggingface SBERT API - Part 1](deep_learning/transformer/huggingface_sbert_api_part1.md) | Este artículo introduce la API de Huggingface Sentence-BERT (SBERT), explicando su propósito, aplicaciones y cómo usarla para incrustar oraciones y calcular similitudes. | SBERT, Sentence Transformer, Embeddings         |
| [Huggingface SBERT API - Part 2](deep_learning/transformer/huggingface_sbert_api_part2.md) | Esta continuación de la guía de la API SBERT cubre el uso avanzado, la afinación de modelos y la integración de SBERT con varias aplicaciones. | SBERT, Sentence Transformer, Embeddings |
| [Huggingface Transformer Auto Class API - Part 1](deep_learning/transformer/huggingface_transformer_auto_class_api_part1.md) | Este artículo proporciona una visión general de la API de Huggingface Transformer Auto Class, detallando sus características, configuración y uso básico para diferentes tareas de NLP. | Transformer, Auto Class, NLP, API             |
| [Huggingface Transformer Auto Class API - Part 2](deep_learning/transformer/huggingface_transformer_auto_class_api_part2.md) | Una mirada más profunda a la API de Transformer Auto Class, explorando configuraciones personalizadas, optimización de modelos y casos de uso. | Transformer, Auto Class, NLP, API |
| [Huggingface Transformer Pipeline API](deep_learning/transformer/huggingface_transformer_pipeline_api.md) | Esta guía explica la API de Huggingface Transformer Pipeline, mostrando su facilidad de uso para varias tareas de NLP como clasificación de texto, reconocimiento de entidades nombradas y generación de texto. | Transformer Pipeline |
| [Huggingface CLIP API](deep_learning/transformer/model_multimodal/huggingface_clip_api.md)                     | Este artículo introduce la API de Huggingface CLIP (Contrastive Language-Image Pre-training), explicando su propósito, aplicaciones y cómo usarla para incrustaciones de imágenes y texto. | Huggingface, CLIP, API |
| [Huggingface LLaVA Next API](deep_learning/transformer/model_multimodal/huggingface_llava_next_api.md)               | Esta guía detalla la API de Huggingface LLaVA Next, describiendo sus características, configuración y uso para tareas avanzadas de comprensión del lenguaje. | LLaVA, MultiModal, API |
| [Huggingface Vision Transformer (ViT) API](deep_learning/transformer/model_vision/huggingface_vit_api.md)       | Este artículo proporciona una visión general de la API de Huggingface Vision Transformer (ViT), explicando su uso para la clasificación de imágenes y otras tareas de visión. | ViT, Vision Transformer, Image Classification, API |
| [Huggingface Diffusers API](deep_learning/diffusion/huggingface_diffusers_api.md)                | Este artículo proporciona una visión general de la API de Huggingface Diffusers, explicando su funcionalidad y uso para generar imágenes a partir de descripciones de texto. | Diffusers API, Image Generation, Text-to-Image, Image-to-Image |
| [Huggingface Diffusers Chained Pipeline](deep_learning/diffusion/huggingface_diffusers_chained_pipeline.md)   | Esta guía explica cómo crear pipelines encadenados usando la API de Huggingface Diffusers, mostrando cómo combinar múltiples modelos para tareas complejas. | Diffusers API, Chained Pipeline |
| [Huggingface Diffusers Pipeline API](deep_learning/diffusion/huggingface_diffusers_pipeline_api.md)       | Una mirada en profundidad a la API de Huggingface Diffusers Pipeline, detallando sus características, configuración y aplicaciones para la generación de imágenes y texto. | Diffusers Pipeline API |

### Operaciones con Tensores

| Título                | Descripción           | Palabras Clave        |
|-----------------------|-----------------------|-----------------------|
| [Einops Einsum](deep_learning/coding/einops_einsum.md)                            | Una introducción a la función einsum en la biblioteca einops, explicando su sintaxis, uso y aplicaciones en operaciones con tensores. | einops, einsum, tensor operations |
| [Einops Rearrange](deep_learning/coding/einops_rearrange.md)                         | Esta guía detalla la función rearrange en la biblioteca einops, mostrando cómo manipular y transformar eficientemente las formas de los tensores. | einops, einsum, tensor operations |

### Conjuntos de Datos

| Título                | Descripción           | Palabras Clave        |
|-----------------------|-----------------------|-----------------------|
| [Huggingface Datasets Loading](deep_learning/dataset/huggingface_datasets_loading.md)           | Este artículo cubre cómo cargar y preprocesar conjuntos de datos utilizando la biblioteca Huggingface Datasets, incluyendo el manejo de varios formatos y fuentes de datos. | Huggingface, Datasets |
| [Huggingface Datasets Main Classes](deep_learning/dataset/huggingface_datasets_main_classes.md) | Una guía comprensiva sobre las clases principales de la biblioteca Huggingface Datasets, explicando sus funcionalidades y casos de uso. | Huggingface, Datasets, Main Classes |
| [Guía de Auto-Instrucción de Alpaca](deep_learning/dataset/alpaca_self_instruct_guide.md)           | Esta guía proporciona una visión general completa del proceso de Auto-Instrucción utilizando Alpaca, incluyendo instrucciones paso a paso y ejemplos. | Alpaca, Self-Instruct |

### Entrenamiento de Modelos

| Título                | Descripción           | Palabras Clave        |
|-----------------------|-----------------------|-----------------------|
| [Huggingface Transformer Trainer API](deep_learning/training/huggingface_transformer_trainer_finetune.md) | Esta guía explora cómo afinar modelos de transformers utilizando la API de Huggingface Trainer, cubriendo la configuración, el entrenamiento y los procesos de evaluación. | Huggingface, Transformer, Trainer API, SFT |
| [Huggingface Evaluate API](deep_learning/training/huggingface_evaluate_api.md) | Este artículo introduce la API de Huggingface Evaluate, detallando su propósito, configuración y uso para evaluar modelos de aprendizaje automático. | Huggingface, Evaluate API, Metric |


## Nuestros Objetivos

Los objetivos de AI Power Source son los siguientes:

- **Comprender Efectivamente los Algoritmos de AI**: Profundizar en la comprensión de varios algoritmos de AI mediante la lectura de código.
- **Aprender Rápidamente Bibliotecas de AI**: Acelerar el dominio de varias bibliotecas de AI utilizando numerosos programas de ejemplo.
- **Analizar Código**: Promover el aprendizaje mediante el análisis del código de diversos frameworks y aplicaciones de AI.
- **Aprender Técnicas de Entrenamiento de Modelos**: Dominar rápidamente las habilidades necesarias para el entrenamiento de modelos de AI a través de abundantes programas de ejemplo y el intercambio de experiencias.
- **Diseño de Procesos MLOps**: Aprender y practicar el diseño de procesos MLOps para mejorar la eficiencia y la fiabilidad del despliegue y gestión de modelos.
- **Diseño de Arquitectura de Sistemas**: Aprender el diseño de arquitectura de sistemas de aplicaciones de AI a través de estudios de caso, incluyendo el diseño de arquitecturas de software y nube.

## Cómo Contribuir

Si deseas ayudar con las siguientes tareas, te invitamos a unirte a nosotros:

- **Ayudar a Traducir Artículos Existentes**: Ayudar a traducir y mejorar los artículos y materiales educativos existentes.
- **Contribuir con Nuevos Artículos**: Contribuir con al menos un artículo nuevo cada mes, compartiendo tus conocimientos y experiencias en AI.

## Únete a Nosotros

Damos la bienvenida a todas las personas interesadas en la tecnología AI a unirse a nuestra comunidad, independientemente de su nivel de experiencia. Cada contribución que hagas jugará un papel significativo en la promoción y desarrollo de la tecnología AI.

## Contáctanos

Si tienes alguna pregunta o sugerencia, por favor contáctanos a través de [GitHub Issues](https://github.com/ksmooi/ai_power/issues).

¡Gracias por tu participación y apoyo!