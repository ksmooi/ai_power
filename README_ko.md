[ [English](README.md) ] [ [Español](README_es.md) ] [ [简体中文](README_zhcn.md) ] [ [繁體中文](README_zhtw.md) ] [ [日本語](README_ja.md) ]

# AI Power

AI 기술은 빠른 속도로 발전하고 있으며, 새로운 알고리즘과 AI 라이브러리가 끊임없이 등장하고 진화하고 있습니다. 더 많은 사람들이 최신 AI 혁신 기술을 숙달하고 오픈 소스 프로젝트에 적극 참여할 수 있도록 하기 위해 AI Power Source를 만들었습니다. AI 기술의 최첨단을 탐구하고 미래를 형성하는 데 기여하는 여정에 동참하세요!

## 글 분류

### 코드 기반 알고리즘 학습

| 제목                 | 설명           | 키워드              |
|-----------------------|-----------------------|-----------------------|
| [Understanding Transformer Attentions](deep_learning/transformer/transformer_attentions.md)                   | 트랜스포머의 어텐션 메커니즘에 대한 심층 설명으로, 셀프 어텐션, 멀티 헤드 어텐션 및 최신 NLP 모델에서의 구현을 다룹니다. | Transformers, Self-Attention, MHA |
| [The Vanilla Transformer Explained](deep_learning/transformer/vanilla_transformer_explained_enus.md)       | 바닐라 트랜스포머 모델에 대한 종합 가이드로, 아키텍처, 구성 요소 및 시퀀스-투-시퀀스 작업에 대한 전방 패스 프로세스를 자세히 설명합니다. | vanilla Transformer, Architecture, Sequence-to-Sequence |
| [Inside CLIP](deep_learning/transformer/model_multimodal/huggingface_clip_explained.md)               | CLIP 모델에 대한 심층 설명으로, 아키텍처, 훈련 과정 및 이미지와 텍스트를 연결하는 응용 프로그램을 다룹니다. | CLIP, Architecture |
| [Deep Dive into LLaVA](deep_learning/transformer/model_multimodal/llava_implementation_explained.md)           | LLaVA 모델의 구현에 대한 종합 가이드로, 아키텍처, 구성 요소 및 언어 이해 작업을 향상시키는 방법을 탐구합니다. | LLaVA, Architecture, MultiModal |
| [Deep Dive into Vision Transformer](deep_learning/transformer/model_vision/huggingface_vit_explained.md)                | Vision Transformer (ViT) 모델에 대한 심층 설명으로, 아키텍처, 주요 구성 요소 및 컴퓨터 비전 작업에의 응용을 다룹니다. | Vision Transformer, ViT, Architecture |
| [AutoEncoder Explained](deep_learning/diffusion/autoencoder_explained.md)                    | 오토인코더에 대한 심층 설명으로, 아키텍처, 유형 및 데이터 압축과 특징 학습에서의 응용을 다룹니다. | AutoEncoder, VAE, Architecture |

### Huggingface API

| 제목                 | 설명           | 키워드              |
|-----------------------|-----------------------|-----------------------|
| [Huggingface SBERT API - Part 1](deep_learning/transformer/huggingface_sbert_api_part1.md) | Huggingface Sentence-BERT (SBERT) API를 소개하는 이 기사에서는 문장 임베딩과 유사성 계산을 위한 목적, 응용 및 사용 방법을 설명합니다. | SBERT, Sentence Transformer, Embeddings         |
| [Huggingface SBERT API - Part 2](deep_learning/transformer/huggingface_sbert_api_part2.md) | SBERT API 가이드의 이 연속 기사에서는 고급 사용법, 모델 파인튜닝 및 다양한 응용 프로그램과의 통합을 다룹니다. | SBERT, Sentence Transformer, Embeddings |
| [Huggingface Transformer Auto Class API - Part 1](deep_learning/transformer/huggingface_transformer_auto_class_api_part1.md) | Huggingface Transformer Auto Class API의 개요를 제공하며, 다양한 NLP 작업을 위한 기능, 설정 및 기본 사용법을 설명합니다. | Transformer, Auto Class, NLP, API             |
| [Huggingface Transformer Auto Class API - Part 2](deep_learning/transformer/huggingface_transformer_auto_class_api_part2.md) | Transformer Auto Class API에 대한 더 깊은 이해를 제공하며, 사용자 정의 구성, 모델 최적화 및 사용 사례를 탐구합니다. | Transformer, Auto Class, NLP, API |
| [Huggingface Transformer Pipeline API](deep_learning/transformer/huggingface_transformer_pipeline_api.md) | Huggingface Transformer Pipeline API를 설명하며, 텍스트 분류, 명명된 엔터티 인식 및 텍스트 생성과 같은 다양한 NLP 작업에 대한 사용의 용이성을 보여줍니다. | Transformer Pipeline |
| [Huggingface CLIP API](deep_learning/transformer/model_multimodal/huggingface_clip_api.md)                     | Huggingface CLIP (대조적 언어-이미지 사전 훈련) API를 소개하는 이 기사에서는 그 목적, 응용 프로그램 및 이미지와 텍스트 임베딩을 위한 사용 방법을 설명합니다. | Huggingface, CLIP, API |
| [Huggingface LLaVA Next API](deep_learning/transformer/model_multimodal/huggingface_llava_next_api.md)               | Huggingface LLaVA Next API의 특징, 설정 및 고급 언어 이해 작업을 위한 사용법을 설명하는 가이드입니다. | LLaVA, MultiModal, API |
| [Huggingface Vision Transformer (ViT) API](deep_learning/transformer/model_vision/huggingface_vit_api.md)       | Huggingface Vision Transformer (ViT) API의 개요를 제공하며, 이미지 분류 및 기타 비전 작업에 대한 사용법을 설명합니다. | ViT, Vision Transformer, Image Classification, API |
| [Huggingface Diffusers API](deep_learning/diffusion/huggingface_diffusers_api.md)                | Huggingface Diffusers API의 개요를 제공하며, 텍스트 설명으로부터 이미지를 생성하기 위한 기능 및 사용법을 설명합니다. | Diffusers API, Image Generation, Text-to-Image, Image-to-Image |
| [Huggingface Diffusers Chained Pipeline](deep_learning/diffusion/huggingface_diffusers_chained_pipeline.md)   | Huggingface Diffusers API를 사용하여 체인 파이프라인을 만드는 방법을 설명하는 가이드로, 여러 모델을 결합하여 복잡한 작업을 수행하는 방법을 보여줍니다. | Diffusers API, Chained Pipeline |
| [Huggingface Diffusers Pipeline API](deep_learning/diffusion/huggingface_diffusers_pipeline_api.md)       | Huggingface Diffusers Pipeline API의 특징, 설정 및 이미지와 텍스트 생성 응용 프로그램에 대한 사용법을 자세히 설명합니다. | Diffusers Pipeline API |

### 텐서 연산

| 제목                 | 설명           | 키워드              |
|-----------------------|-----------------------|-----------------------|
| [Einops Einsum](deep_learning/coding/einops_einsum.md)                            | einops 라이브러리의 einsum 함수에 대한 소개로, 구문, 사용법 및 텐서 연산에서의 응용을 설명합니다. | einops, einsum, tensor operations |
| [Einops Rearrange](deep_learning/coding/einops_rearrange.md)                         | einops 라이브러리의 rearrange 함수에 대한 가이드로, 텐서 모양을 효율적으로 조작하고 변환하는 방법을 보여줍니다. | einops, einsum, tensor operations |

### 데이터셋

| 제목                 | 설명           | 키워드              |
|-----------------------|-----------------------|-----------------------|
| [Huggingface Datasets Loading](deep_learning/dataset/huggingface_datasets_loading.md)           | Huggingface Datasets 라이브러리를 사용하여 데이터셋을 로드하고 전처리하는 방법을 다루며, 다양한 데이터 형식과 소스를 처리하는 방법을 설명합니다. | Huggingface, Datasets |
| [Huggingface Datasets Main Classes](deep_learning/dataset/huggingface_datasets_main_classes.md) | Huggingface Datasets 라이브러리의 주요 클래스에 대한 종합 가이드로, 그 기능과 사용 사례를 설명합니다. | Huggingface, Datasets, Main Classes |
| [Alpaca 셀프 인스트럭트 가이드](deep_learning/dataset/alpaca_self_instruct_guide.md)           | 이 가이드는 Alpaca를 사용한 셀프 인스트럭트 프로세스에 대한 포괄적인 개요를 제공하며, 단계별 지침과 예제를 포함합니다. | Alpaca, Self-Instruct |

### 모델 훈련

| 제목                 | 설명           | 키워드              |
|-----------------------|-----------------------|-----------------------|
| [Huggingface Transformer Trainer API](deep_learning/training/huggingface_transformer_trainer_finetune.md) | Huggingface Trainer API를 사용하여 트랜스포머 모델을 파인튜닝하는 방법을 탐구하는 가이드로, 설정, 훈련 및 평가 과정을 다룹니다. | Huggingface, Transformer, Trainer API, SFT |
| [Huggingface Evaluate API](deep_learning/training/huggingface_evaluate_api.md) | Huggingface Evaluate API를 소개하는 이 기사에서는 목적, 설정 및 기계 학습 모델 평가를 위한 사용법을 설명합니다. | Huggingface, Evaluate API, Metric |


## 우리의 목표

AI Power Source의 목표는 다음과 같습니다:

- **AI 알고리즘을 효과적으로 이해하기**: 코드를 읽어 다양한 AI 알고리즘에 대한 이해를 심화합니다.
- **AI 라이브러리를 빠르게 배우기**: 많은 예제 프로그램을 사용하여 다양한 AI 라이브러리를 빠르게 습득합니다.
- **코드 분석**: 다양한 AI 프레임워크 및 애플리케이션의 코드를 분석하여 학습을 촉진합니다.
- **모델 훈련 기술 학습**: 풍부한 예제 프로그램과 경험 공유를 통해 AI 모델 훈련에 필요한 기술을 빠르게 습득합니다.
- **MLOps 프로세스 설계**: 모델 배포 및 관리의 효율성과 신뢰성을 향상시키기 위해 MLOps 프로세스 설계를 학습하고 실천합니다.
- **시스템 아키텍처 설계**: 사례 연구를 통해 소프트웨어 및 클라우드 아키텍처 설계를 포함한 AI 응용 프로그램의 시스템 아키텍처 설계를 학습합니다.

## 기여 방법

다음 작업에 도움을 주고 싶다면 저희와 함께 하시기를 환영합니다:

- **기존 글 번역 지원**: 기존 글과 교육 자료를 번역하고 개선하는 데 도움을 줍니다.
- **새 글 기여**: 매월 최소 한 편의 새 글을 기여하여 귀하의 AI 지식과 경험을 공유합니다.

## 가입하기

경험 수준에 관계없이 AI 기술에 관심이 있는 모든 분들을 저희 커뮤니티에 초대합니다. 귀하의 모든 기여는 AI 기술의 대중화와 발전에 중요한 역할을 할 것입니다.

## 문의하기

질문이나 제안이 있으시면 [GitHub Issues](https://github.com/ksmooi/ai_power/issues)를 통해 저희에게 연락해 주세요.

참여와 지원에 감사드립니다!